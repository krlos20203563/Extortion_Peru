d3heatmap(heatmap_data, scale = "column", colors="Spectral")
View(heatmap_data)
pregunta5 <- pregunta5 %>%
mutate(relacion = con_señales/sin_señales)
head(pregunta5)
pregunta5 <- pregunta5 %>%
group_by(departamento) %>%
summarise(
total_casos = n(),
graves = sum(enfermedad == "grave"),
sin_señales = sum(enfermedad == "sin"),
con_señales = sum(enfermedad == "con")
)
knitr::opts_chunk$set(echo = TRUE)
library(rio)
data=import("https://github.com/krlos20203563/ASIE_2024-1/raw/main/datos_abiertos_vigilancia_dengue.csv")
summary(data$edad)
str(data)
library(dplyr)
table(data$enfermedad)
data$enfermedad <- gsub("DENGUE CON SEÑALES DE ALARMA", "con", data$enfermedad)
data$enfermedad <- gsub("DENGUE SIN SEÑALES DE ALARMA", "sin", data$enfermedad)
data$enfermedad <- gsub("DENGUE GRAVE", "grave", data$enfermedad)
table(data$enfermedad)
data=filter(data, enfermedad=="con" | enfermedad=="sin" | enfermedad=="grave")
data$enfermedad=as.factor(data$enfermedad)
table(data$enfermedad)
summary(data$edad)
library(lsr)
EdadxYear = data |>
group_by(year) |>
summarise(media = mean(edad, na.rm=T))
EdadxYear
library(ggplot2)
library(ggthemes)
# Crear el gráfico de líneas
library(ggplot2)
ggplot(EdadxYear, aes(x = year, y = media)) +
geom_line(color = "blue", size = 1.5) +
geom_point(color = "red", size = 3) +
labs(title = "Edad promedio de personas contagiadas de dengue por año",
x = "Año",
y = "Edad") +
theme_economist() +
theme(legend.key.size = unit(1, "lines"),  # Tamaño de la leyenda
plot.title = element_text(size = 10))  # Tamaño del título
pregunta3 <- data %>%
group_by(year) %>%
summarise(
total_casos = n(),
graves = sum(enfermedad == "grave"),
sin_señales = sum(enfermedad == "sin"),
con_señales = sum(enfermedad == "con")
)
library(ggplot2)
library(ggthemes)
grafico_total <- ggplot(pregunta3, aes(x = year, y = total_casos)) +
geom_line(size=1) +
geom_point(color = "red", size = 3) +
labs(title = "Total de casos de Dengue a lo largo de los años",
x = "Año",
y = "Total de casos") +
theme_update()
grafico_con_alarma <- ggplot(pregunta3, aes(x = year, y = con_señales)) +
geom_line() +
geom_point(color = "red", size = 3) +
labs(title = "Casos de Dengue con Alarma a lo largo de los años",
x = "Año",
y = "Casos con Alarma") +
theme_stata()
grafico_sin_alarma <- ggplot(pregunta3, aes(x = year, y = sin_señales)) +
geom_line() +
geom_point(color = "red", size = 3) +
labs(title = "Casos de Dengue sin Alarma a lo largo de los años",
x = "Año",
y = "Casos sin Alarma") +
theme_test()
grafico_graves <- ggplot(pregunta3, aes(x = year, y = graves)) +
geom_line() +
geom_point(color = "red", size = 3) +
labs(title = "Casos de Dengue Grave a lo largo de los años",
x = "Año",
y = "Casos Graves") +
theme_minimal()
print(grafico_total)
print(grafico_con_alarma)
print(grafico_sin_alarma)
print(grafico_graves)
pregunta4 <- data %>%
group_by(departamento, provincia, year) %>%
summarize(
con_alarma = sum(enfermedad == "con"),
sin_alarma = sum(enfermedad == "sin"),
graves = sum(enfermedad == "graves")
)
# Mostrar los primeros registros de la base de datos resumida
head(pregunta4)
pregunta4 <- pregunta4 %>%
mutate(total_contagios = con_alarma + sin_alarma + graves)
head(pregunta4)
provyear <- pregunta4 %>%
group_by(departamento, provincia) %>%
summarise(total_historico = sum(total_contagios))
summary(provyear$total_historico)
provyear=filter(provyear, total_historico>3530)
library(ggplot2)
# Crear el gráfico de puntos
puntos <- ggplot(provyear, aes(x = departamento, y = total_historico, label = provincia)) +
geom_point(color = "red", size = 3) +
geom_text(size = 1.9, vjust = -0.5) +
labs(title = "Provincias con mayor número de casos de dengue",
x = "Departamentos", y = "Total de casos") +
theme_solarized() +
theme(plot.title = element_text(hjust = 0.5),
plot.margin = unit(c(0.5, 0.5, 0.5, 0.5), "cm"),
axis.text.x = element_text(size = 4.5),
axis.text.y = element_text(size = 5),
axis.title.x = element_text(size = 10),
axis.title.y = element_text(size = 10))
puntos
table(data$departamento)
pregunta5 <- data %>% filter_all(all_vars(. != "\\N"))
table(pregunta5$departamento)
pregunta5 <- pregunta5 %>%
group_by(departamento) %>%
summarise(
total_casos = n(),
graves = sum(enfermedad == "grave"),
sin_señales = sum(enfermedad == "sin"),
con_señales = sum(enfermedad == "con")
)
head(pregunta5)
pregunta5 <- pregunta5 %>%
mutate(relacion = con_señales/sin_señales)
head(pregunta5)
library(knitr)
library(heatmap3)
library(plotly)
# Preparar los datos para el heatmap
heatmap_data <- pregunta5 %>%
select(con_señales, sin_señales, relacion) %>%
as.matrix()
# Añadir nombres de fila
rownames(heatmap_data) <- pregunta5$departamento
# Crear el heatmap
heatmap(heatmap_data, Rowv = NA, Colv = NA, scale = "none",
main = "Casos de Dengue con y sin Síntomas por Región",
xlab = "Tipo de Caso", ylab = "Región",
col = heat.colors(256))
if (!require("devtools")) install.packages("devtools")
devtools::install_github("talgalili/d3heatmap")
library(d3heatmap)
d3heatmap(mtcars, scale = "column", colors = "Spectral")
d3heatmap(heatmap_data, scale = "column", colors="Spectral",)
View(heatmap_data)
library(d3heatmap)
d3heatmap(heatmap_data, scale = "column", colors="Spectral",)
knitr::opts_chunk$set(echo = TRUE)
install.packages("ggx")
## Library to produce network graphs
library(igraph)
library(haven)
library(foreign)
library(lubridate)
library(dplyr)
library(ggplot2)
#set your working directory
#load Data
load("USCongressUntil-01012022.RData")
#Select only the names of the members of Congress stored in Column 3
select.names<-names(table(boca.df[,3]))
#Create a data.frame that includes only members of congress that RT other
#members of Congress
congress <- data.frame(boca.df[boca.df[,9] %in% select.names, ])
# Create Network
#Select the directed dyads to create the network object
data<-cbind(c(congress[,3]),c(congress[,9]))
#Open a graph
net <- graph.empty()
#Add the name of the members of Congress to the nodes.
net <- add.vertices(net, length(unique(c(data))),name=as.character(unique(c(data))))
#Add the dyads.
net <- add.edges(net, t(data))
#Add variables to the nodes and edges.
E(net)$text <- congress$text
E(net)$name.auth <- congress$rtscreenname
E(net)$name.hub <- congress$screenname
#Add the eigenvector centrality as a variable
V(net)$eig<-evcent(net)$vector
#Add the in-degree as a variable
V(net)$ind<- degree(net,mode="in")
#Add the out-degree as a variable
V(net)$outd<- degree(net,mode="out")
#Add color to the edges if needed
E(net)$color <- "gray"
#Add som other covariates such as the count of friends in the tweet.
E(net)$friends <- congress$friends
### Community detection, retain the top communities
my.com.fast <- walktrap.community(net)
V(net)$membership <- my.com.fast$membership
sel.com<-names(tail(sort(table(V(net)$membership)),n=4))
collect.nodes<- which(V(net)$membership==sel.com[1])
for(i in 2:4){collect.nodes<- c(collect.nodes,which(V(net)$membership==sel.com[i]))}
#Keep only the top four communities
net <- induced.subgraph(graph=net,vids=collect.nodes)
summary(net)
## Estimate FR Layout and add the variables to your network
l <-layout_with_fr(net, grid = c("nogrid"))
V(net)$l1<-l[,1]
V(net)$l2<-l[,2]
#Plot
tiff(filename = paste("Basic Network Plot.tiff",sep=""), width = 8, height = 8, units = "in", pointsize = 8, compression = c("lzw"),  bg = "white", res = 300)
plot(V(net)$l1,V(net)$l2, col=V(net)$membership, cex=log(V(net)$ind)/5, pch=16, xlab="", ylab="", yaxt='n', xaxt='n')
dev.off()
pdf(file = "Basic Network Plot.pdf", 8, 8, pointsize=5, compress=TRUE)
plot(V(net)$l1,V(net)$l2, col=V(net)$membership, cex=log(V(net)$ind)/5, pch=16, xlab="", ylab="", yaxt='n', xaxt='n')
dev.off()
# Make a table of the number of tweets Most active Authorities com 1
for(i in 1:4){
d <- degree(induced.subgraph(graph=net, vids=which(V(net)$membership==i)), mode="in")
d <- as.data.frame(sort(d,decreasing = FALSE))
colnames(d) <- c("Tweets")
print(tail(d))
#windows()
png(paste("USA Congress Community ",i,".png",sep=""), w=700, h=1000)
par(mar=c(5,10,2,2))
with(tail(d,n=30), barplot(Tweets, names=tail(rownames(d),n=30), horiz=T, las=1, main=paste("Community - Net ", i, sep=""), col=i))
dev.off()
}
###Merge Membership to Auth
matrix2<- as.data.frame(cbind(V(net)$name,V(net)$membership))
vector2<- as.data.frame(E(net)$name.auth)
colnames(matrix2)<- c("name.auth","membership.auth")
colnames(vector2)<- c("name.auth")
E(net)$membership.auth<-left_join(x=vector2, y=matrix2, by="name.auth")$membership.auth
###Merge Membership to Hub
vector2<- as.data.frame(E(net)$name.hub)
colnames(matrix2)<- c("name.hub","membership.hub")
colnames(vector2)<- c("name.hub")
E(net)$membership.hub<-left_join(x=vector2, y=matrix2, by="name.hub")$membership.hub
summary(net)
tail(sort(table(E(net)$membership.auth)),30)
collect.house<- which(V(net)$membership<=2)
net.house<-induced.subgraph(graph=net,vids=collect.house)
install.packages("quanteda")
#############################
## Create adjacency matrices
#############################
res.al <- .Call(igraph:::C_R_igraph_get_adjlist, net, 3, PACKAGE = "igraph")
collect.house<- which(V(net)$membership<=2)
net.house<-induced.subgraph(graph=net,vids=collect.house)
##################################################
##
##  Functions loaded
##
##################################################
library(devtools)
library(quanteda)
library(quanteda.textstats)
library(quanteda.textmodels)
library(quanteda.textplots)
library(tm)
library(readtext)
library(stringr)
library(tidytext)
my.text <- E(net.house)$text
republicans<- ifelse(E(net.house)$membership.hub==1,1,0)
table(republicans)
myCorpus<-corpus(my.text)
docvars(myCorpus, "republicans") <- republicans
toks_tweets <- tokens(myCorpus, remove_punct = TRUE)
toks_tweets <- tokens_remove(toks_tweets, pattern = stopwords("en"))
dfmat_tweets <- dfm(toks_tweets)
dfmat_tweets <- dfm_select(dfmat_tweets, pattern = "#*")
tstat_freq <- textstat_frequency(dfmat_tweets, n = 16, groups = republicans)
head(tstat_freq, 32)
dfm_group<-dfm_group(dfmat_tweets, republicans)
textplot_wordcloud(dfm_group, color = c("darkgreen", "blue"))
dfmat_tweets %>%
textstat_frequency(.,n = 15) %>%
ggplot(aes(x = reorder(feature, frequency), y = frequency)) +
geom_point() +
coord_flip() +
labs(x = NULL, y = "Frequency") +
theme_minimal()
ggsave("Frequency Accounts US Congress.tiff", width = 12, height = 8, units = "in", pointsize = 12, bg = "white")
head(textstat_keyness(dfmat_tweets, target=republicans==0, measure="chi2"), n=30)
compareText<-textstat_keyness(dfmat_tweets, target=republicans==0, measure="chi2")
textplot_keyness(compareText,
color = c("blue", "red"),
labelcolor = "gray30",
labelsize = 4,
n = 30L)
ggsave("Compare all2 US House.tiff", width = 12, height = 8, units = "in", pointsize = 12, bg = "white")
install.packages("quanteda.textmodels")
install.packages("quanteda.textplots")
install.packages("quanteda.textstats")
install.packages("tm")
install-packages("readtext")
install.packages("readtext")
install.packages("stringr")
install.packages("stringr")
install.packages("stringr")
install.packages("tidytext")
##################################################
##
##  Functions loaded
##
##################################################
library(devtools)
library(quanteda)
library(quanteda.textstats)
library(quanteda.textmodels)
library(quanteda.textplots)
library(tm)
library(readtext)
library(stringr)
library(tidytext)
my.text <- E(net.house)$text
## Library to produce network graphs
library(igraph)
library(haven)
library(foreign)
library(lubridate)
library(dplyr)
library(ggplot2)
#set your working directory
#load Data
load("USCongressUntil-01012022.RData")
#Select only the names of the members of Congress stored in Column 3
select.names<-names(table(boca.df[,3]))
#Create a data.frame that includes only members of congress that RT other
#members of Congress
congress <- data.frame(boca.df[boca.df[,9] %in% select.names, ])
# Create Network
#Select the directed dyads to create the network object
data<-cbind(c(congress[,3]),c(congress[,9]))
#Open a graph
net <- graph.empty()
#Add the name of the members of Congress to the nodes.
net <- add.vertices(net, length(unique(c(data))),name=as.character(unique(c(data))))
#Add the dyads.
net <- add.edges(net, t(data))
#Add variables to the nodes and edges.
E(net)$text <- congress$text
E(net)$name.auth <- congress$rtscreenname
E(net)$name.hub <- congress$screenname
#Add the eigenvector centrality as a variable
V(net)$eig<-evcent(net)$vector
#Add the in-degree as a variable
V(net)$ind<- degree(net,mode="in")
#Add the out-degree as a variable
V(net)$outd<- degree(net,mode="out")
#Add color to the edges if needed
E(net)$color <- "gray"
#Add som other covariates such as the count of friends in the tweet.
E(net)$friends <- congress$friends
### Community detection, retain the top communities
my.com.fast <- walktrap.community(net)
V(net)$membership <- my.com.fast$membership
sel.com<-names(tail(sort(table(V(net)$membership)),n=4))
collect.nodes<- which(V(net)$membership==sel.com[1])
for(i in 2:4){collect.nodes<- c(collect.nodes,which(V(net)$membership==sel.com[i]))}
#Keep only the top four communities
net <- induced.subgraph(graph=net,vids=collect.nodes)
summary(net)
## Estimate FR Layout and add the variables to your network
l <-layout_with_fr(net, grid = c("nogrid"))
V(net)$l1<-l[,1]
V(net)$l2<-l[,2]
#Plot
tiff(filename = paste("Basic Network Plot.tiff",sep=""), width = 8, height = 8, units = "in", pointsize = 8, compression = c("lzw"),  bg = "white", res = 300)
plot(V(net)$l1,V(net)$l2, col=V(net)$membership, cex=log(V(net)$ind)/5, pch=16, xlab="", ylab="", yaxt='n', xaxt='n')
dev.off()
pdf(file = "Basic Network Plot.pdf", 8, 8, pointsize=5, compress=TRUE)
plot(V(net)$l1,V(net)$l2, col=V(net)$membership, cex=log(V(net)$ind)/5, pch=16, xlab="", ylab="", yaxt='n', xaxt='n')
dev.off()
# Make a table of the number of tweets Most active Authorities com 1
for(i in 1:4){
d <- degree(induced.subgraph(graph=net, vids=which(V(net)$membership==i)), mode="in")
d <- as.data.frame(sort(d,decreasing = FALSE))
colnames(d) <- c("Tweets")
print(tail(d))
#windows()
png(paste("USA Congress Community ",i,".png",sep=""), w=700, h=1000)
par(mar=c(5,10,2,2))
with(tail(d,n=30), barplot(Tweets, names=tail(rownames(d),n=30), horiz=T, las=1, main=paste("Community - Net ", i, sep=""), col=i))
dev.off()
}
###Merge Membership to Auth
matrix2<- as.data.frame(cbind(V(net)$name,V(net)$membership))
vector2<- as.data.frame(E(net)$name.auth)
colnames(matrix2)<- c("name.auth","membership.auth")
colnames(vector2)<- c("name.auth")
E(net)$membership.auth<-left_join(x=vector2, y=matrix2, by="name.auth")$membership.auth
###Merge Membership to Hub
vector2<- as.data.frame(E(net)$name.hub)
colnames(matrix2)<- c("name.hub","membership.hub")
colnames(vector2)<- c("name.hub")
E(net)$membership.hub<-left_join(x=vector2, y=matrix2, by="name.hub")$membership.hub
summary(net)
tail(sort(table(E(net)$membership.auth)),30)
collect.house<- which(V(net)$membership<=2)
net.house<-induced.subgraph(graph=net,vids=collect.house)
##################################################
##
##  Functions loaded
##
##################################################
library(devtools)
library(quanteda)
library(quanteda.textstats)
library(quanteda.textmodels)
library(quanteda.textplots)
library(tm)
library(readtext)
library(stringr)
library(tidytext)
my.text <- E(net.house)$text
republicans<- ifelse(E(net.house)$membership.hub==1,1,0)
table(republicans)
myCorpus<-corpus(my.text)
docvars(myCorpus, "republicans") <- republicans
toks_tweets <- tokens(myCorpus, remove_punct = TRUE)
toks_tweets <- tokens_remove(toks_tweets, pattern = stopwords("en"))
dfmat_tweets <- dfm(toks_tweets)
dfmat_tweets <- dfm_select(dfmat_tweets, pattern = "#*")
tstat_freq <- textstat_frequency(dfmat_tweets, n = 16, groups = republicans)
head(tstat_freq, 32)
dfm_group<-dfm_group(dfmat_tweets, republicans)
textplot_wordcloud(dfm_group, color = c("darkgreen", "blue"))
dfmat_tweets %>%
textstat_frequency(.,n = 15) %>%
ggplot(aes(x = reorder(feature, frequency), y = frequency)) +
geom_point() +
coord_flip() +
labs(x = NULL, y = "Frequency") +
theme_minimal()
ggsave("Frequency Accounts US Congress.tiff", width = 12, height = 8, units = "in", pointsize = 12, bg = "white")
head(textstat_keyness(dfmat_tweets, target=republicans==0, measure="chi2"), n=30)
compareText<-textstat_keyness(dfmat_tweets, target=republicans==0, measure="chi2")
textplot_keyness(compareText,
color = c("blue", "red"),
labelcolor = "gray30",
labelsize = 4,
n = 30L)
ggsave("Compare all2 US House.tiff", width = 12, height = 8, units = "in", pointsize = 12, bg = "white")
#############################
## Create adjacency matrices
#############################
res.al <- .Call(igraph:::C_R_igraph_get_adjlist, net, 3, PACKAGE = "igraph")
plot(cars)
install.packages("vitae")
install.packages("tinytex")
install.packages("tinytex")
install.packages("vitae")
install.packages("vitae")
install.packages("tinytex")
install.packages("tinytex")
library(vitae)
knitr::opts_chunk$set(echo = TRUE)
library(rio)
data=import("Modulo_I.sav")
setwd("C:/Users/Carlos Daniel/Downloads/ENVEE_II")
library(rio)
data=import("Modulo_II.sav")
View(data)
table(data$P01_03)
593/(14426+593)*100
setwd("C:/Users/Carlos Daniel/Downloads/ENVEP")
extor=import("CAPITULO_604.sav")
View(extor)
setwd("~/Tesis_de_Licenciatura/Extortion_Peru")
setwd("~/Tesis_de_Licenciatura/Extortion_Peru")
pobproy_prov=import("~/Tesis_de_Licenciatura/Extortion_Peru/data/PROYECCION_POB/proypob_PROVINCIAS.xlsx")
library(dplyr)
View(pobproy_prov)
pobproy_prov=filter(pobproy_prov, !is.na(2018))
View(pobproy_prov)
pobproy_prov=filter(pobproy_prov, !is.na("2018"))
pobproy_prov=filter(pobproy_prov, !is.na(c("2")))
pobproy_prov <- filter(pobproy_prov, !is.na(pobproy_prov[[2]]))
View(pobproy_prov)
knitr::opts_chunk$set(echo = TRUE)
c100_2019=import("https://github.com/krlos20203563/Extortion_Peru/raw/refs/heads/main/data/SIUP/SIUP2019/SIUP2019_c100_LISTO.xlsx")
c100_2019=import("https://github.com/krlos20203563/Extortion_Peru/raw/refs/heads/main/data/SIUP/SIUP2019/SIUP2019_c100_LISTO.xlsx")
library(rio)
library(dplyr)
library(magrittr)
library(tidyr)
library(stringi)
c100_2019=import("https://github.com/krlos20203563/Extortion_Peru/raw/refs/heads/main/data/SIUP/SIUP2019/SIUP2019_c100_LISTO.xlsx")
## SIUP 2019
```{r}
c100_2019=import("https://github.com/krlos20203563/Extortion_Peru/raw/refs/heads/main/data/SIUP/SIUP2019/SIUP2019_c100_LISTO.xlsx")
c600_2019=import("https://github.com/krlos20203563/Extortion_Peru/raw/refs/heads/main/data/SIUP/SIUP2019/SIUP2019_c600_LISTO.xlsx")
knitr::opts_chunk$set(echo = TRUE)
library(rio)
c100_2019=import("https://github.com/krlos20203563/Extortion_Peru/raw/refs/heads/main/data/SIUP/SIUP2019/SIUP2019_c100_LISTO.xlsx")
View(c100_2019)
View(c100_2019)
library(foreign) #Paquete para importar datos
library(dplyr) #Paquete de procesamiento de bases de datos
library(car) #Paquete de análisis de datos
library(xtable) #Paquete tablas en LaTeX
setwd("D:/CISEPA_DATA-ANALYTICS/903-Modulo1819")
View(pobproy_prov)
View(c100_2019)
View(extor)
View(data)
View(extor)
setwd("~/Tesis_de_Licenciatura/Extortion_Peru")
